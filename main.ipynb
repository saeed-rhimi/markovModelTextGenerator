{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-08T17:18:17.880763400Z",
     "start_time": "2023-09-08T17:18:17.747686400Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set the random seed to ensure reproducibility of random numbers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61bbd4b07772fc34"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T17:18:17.892768700Z",
     "start_time": "2023-09-08T17:18:17.882755700Z"
    }
   },
   "id": "6d1794b5a6c967b7"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "initial = {} # Start of the phrase\n",
    "first_order = {} # Second word only\n",
    "second_order = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T17:18:17.925085Z",
     "start_time": "2023-09-08T17:18:17.890746600Z"
    }
   },
   "id": "4c80246d04672945"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define a function to remove punctuation "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "595d39013b282360"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    # Use the 'translate' method to remove all punctuation characters from the input string\n",
    "    # The 'string.punctuation' constant provides a set of all punctuation characters\n",
    "    return s.translate(str.maketrans('', '', string.punctuation))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T17:18:18.780354100Z",
     "start_time": "2023-09-08T17:18:18.765922300Z"
    }
   },
   "id": "62f0969070d39276"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define a function to add to dictionary"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41b072d493c45f6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def add2dict(d, k, v):\n",
    "    # Check if the key 'k' is not already in the dictionary 'd'\n",
    "    if k not in d:\n",
    "        # If not, create an empty list as the value associated with key 'k'\n",
    "        d[k] = []\n",
    "    # Append the value 'v' to the list associated with key 'k'\n",
    "    d[k].append(v)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T17:18:31.888691Z",
     "start_time": "2023-09-08T17:18:31.876197Z"
    }
   },
   "id": "715d1fc396b2dd13"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Iterate over lines in file"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "109c397d2ccd7b94"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "for line in open('robert_frost_poe.txt'):\n",
    "    # Remove punctuation, convert to lowercase, and split the line into tokens\n",
    "    tokens = remove_punctuation(line.rstrip().lower()).split()\n",
    "    \n",
    "    # Get the total number of tokens in the line\n",
    "    T = len(tokens)\n",
    "    \n",
    "    # Iterate over each token in the line\n",
    "    for i in range(T):\n",
    "        t = tokens[i]\n",
    "        if i == 0:\n",
    "            # If it's the first token in the line, update the 'initial' dictionary\n",
    "            initial[t] = initial.get(t, 0.) + 1\n",
    "        else:\n",
    "            t_1 = tokens[i-1]\n",
    "            if i == T - 1:\n",
    "                # If it's the last token in the line, add 'END' to 'second_order' dictionary\n",
    "                add2dict(second_order, (t_1, t), 'END')\n",
    "            if i == 1:\n",
    "                # If it's the second token in the line, update the 'first_order' dictionary\n",
    "                add2dict(first_order, t_1, t)\n",
    "            else:\n",
    "                t_2 = tokens[i-2]\n",
    "                # For other tokens, update the 'second_order' dictionary\n",
    "                add2dict(second_order, (t_2, t_1), t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T17:18:36.145120800Z",
     "start_time": "2023-09-08T17:18:36.106386200Z"
    }
   },
   "id": "f165d20ffe35aa2a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Normalize start of phrase counts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adba93e4239beb79"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "initial_total = sum(initial.values())\n",
    "\n",
    "# Normalize the counts of initial words by dividing each count by the total count\n",
    "for t, c in initial.items():\n",
    "    initial[t] = c / initial_total"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T17:19:01.314587600Z",
     "start_time": "2023-09-08T17:19:01.291172800Z"
    }
   },
   "id": "7dc252552fa504e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert list to probability dictionary"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eee83eef8cb755f9"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def list2pdict(ts):\n",
    "    # Create an empty dictionary 'd' to store probabilities\n",
    "    d = {}\n",
    "    \n",
    "    # Get the length of the input list 'ts'\n",
    "    n = len(ts)\n",
    "    \n",
    "    # Count the occurrences of each item in the list and store them in 'd'\n",
    "    for t in ts:\n",
    "        d[t] = d.get(t, 0.) + 1\n",
    "    \n",
    "    # Normalize the counts by dividing each count by the total count 'n'\n",
    "    for t, c in d.items():\n",
    "        d[t] = c / n\n",
    "    \n",
    "    # Return the probability dictionary 'd'\n",
    "    return d"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T17:19:11.828311200Z",
     "start_time": "2023-09-08T17:19:11.820332700Z"
    }
   },
   "id": "e0bc23558bc99e77"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert first and second word transitions to probabilities"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a333a4bf7af0a0e5"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Iterate over the items in the 'first_order' dictionary\n",
    "for t_1, ts in first_order.items():\n",
    "    # Convert the list of items 'ts' into a probability dictionary\n",
    "    first_order[t_1] = list2pdict(ts)\n",
    "    \n",
    "# Iterate over the items in the 'second_order' dictionary\n",
    "for k, ts in second_order.items():\n",
    "    # Convert the list of items 'ts' into a probability dictionary\n",
    "    second_order[k] = list2pdict(ts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T17:19:15.799551400Z",
     "start_time": "2023-09-08T17:19:15.779012100Z"
    }
   },
   "id": "2aaf9065cdd8cd50"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sample word from probability dictionary  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce41e85ad781f637"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Define a function called 'sample_word' that takes a probability dictionary 'd' as input\n",
    "def sample_word(d):\n",
    "    # Generate a random probability 'p0' between 0 and 1\n",
    "    p0 = np.random.random()\n",
    "    \n",
    "    # Initialize a cumulative probability variable\n",
    "    cumulative = 0\n",
    "    \n",
    "    # Iterate over items in the probability dictionary\n",
    "    for t, p in d.items():\n",
    "        cumulative += p\n",
    "        # Check if the cumulative probability exceeds 'p0'\n",
    "        if p0 < cumulative:\n",
    "            # Return the sampled word 't'\n",
    "            return t\n",
    "    \n",
    "    # If no word is sampled, raise an assertion error (should not happen)\n",
    "    assert (False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T17:19:16.643412400Z",
     "start_time": "2023-09-08T17:19:16.632896400Z"
    }
   },
   "id": "bf12bc9f7c781a05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate sentences  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7bdef213f26a08a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Define a function called 'generate' to generate sentences\n",
    "def generate():\n",
    "    # Loop to generate 4 sentences\n",
    "    for i in range(4):\n",
    "        sentence = []\n",
    "        \n",
    "        # Start with a random initial word\n",
    "        w0 = sample_word(initial)\n",
    "        sentence.append(w0)\n",
    "        \n",
    "        # Choose the next word based on the first-order transition probabilities\n",
    "        w1 = sample_word(first_order[w0])\n",
    "        sentence.append(w1)\n",
    "        \n",
    "        # Continue adding words until 'END' is encountered in second-order transition\n",
    "        while True:\n",
    "            w2 = sample_word(second_order[(w0, w1)])\n",
    "            if w2 == 'END':\n",
    "                break\n",
    "            \n",
    "            # Append the word to the sentence and update 'w0' and 'w1'\n",
    "            sentence.append(w2)\n",
    "            w0 = w1\n",
    "            w1 = w2\n",
    "        \n",
    "        # Print the generated sentence\n",
    "        print(' '.join(sentence))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T17:19:17.665734300Z",
     "start_time": "2023-09-08T17:19:17.654241900Z"
    }
   },
   "id": "ad51264de2fb744c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i went to bed alone and left me\n",
      "might just as empty\n",
      "but it isnt as if and thats not all the money goes so fast\n",
      "you couldnt call it living for it aint\n"
     ]
    }
   ],
   "source": [
    "generate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-08T17:19:18.432888400Z",
     "start_time": "2023-09-08T17:19:18.314204800Z"
    }
   },
   "id": "f8b7d9acaac188b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b2756543f9e6fc50"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
